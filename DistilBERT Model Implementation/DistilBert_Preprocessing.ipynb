{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "68c45037-a05c-484e-83c8-928f8b4614e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# CELL 1: Imports & Setup\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ec588cf0-536e-4ff9-bc15-9ad27a1a5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 2: SimpleSMSAugmenter Class\n",
    "# ================================================================\n",
    "\n",
    "class SimpleSMSAugmenter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sms_specific_augmentation(self, text, label):\n",
    "        augmented_texts = [text]\n",
    "        \n",
    "        if label == 0:  # ham\n",
    "            variations = [\n",
    "                text.lower(),\n",
    "                self.add_typos(text),\n",
    "                self.add_emojis(text),\n",
    "                self.shorten_words(text),\n",
    "                self.add_sms_abbreviations(text)\n",
    "            ]\n",
    "        else:  # smish\n",
    "            variations = [\n",
    "                text,\n",
    "                self.vary_urgency_level(text),\n",
    "                self.change_offer_amounts(text),\n",
    "                self.modify_urls_numbers(text)\n",
    "            ]\n",
    "        \n",
    "        augmented_texts.extend([v for v in variations if v != text and len(v) > 10])\n",
    "        return list(set(augmented_texts))\n",
    "    \n",
    "    def add_typos(self, text):\n",
    "        common_typos = {\n",
    "            'the': 'teh', 'you': 'u', 'your': 'ur', 'are': 'r',\n",
    "            'see': 'c', 'why': 'y', 'please': 'pls', 'thanks': 'thx',\n",
    "            'before': 'b4', 'great': 'gr8', 'late': 'l8', 'message': 'msg'\n",
    "        }\n",
    "        words = text.split()\n",
    "        if random.random() < 0.3:\n",
    "            for i, word in enumerate(words):\n",
    "                if word.lower() in common_typos and random.random() < 0.4:\n",
    "                    words[i] = common_typos[word.lower()]\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def add_emojis(self, text):\n",
    "        emojis = ['üòä', 'üòÇ', 'üëç', '‚ù§Ô∏è', 'üôè', 'üòç', 'üòé', 'ü§î', 'üëã', 'üéâ']\n",
    "        if random.random() < 0.4:\n",
    "            return text + ' ' + random.choice(emojis)\n",
    "        return text\n",
    "    \n",
    "    def shorten_words(self, text):\n",
    "        abbreviations = {\n",
    "            'because': 'cuz', 'tomorrow': 'tmrw', 'today': '2day',\n",
    "            'tonight': '2nite', 'for you': '4u', 'see you': 'cu',\n",
    "            'by the way': 'btw', 'oh my god': 'omg', 'laughing out loud': 'lol',\n",
    "            'be right back': 'brb', 'talk to you later': 'ttyl'\n",
    "        }\n",
    "        \n",
    "        lower_text = text.lower()\n",
    "        for full, short in abbreviations.items():\n",
    "            if full in lower_text and random.random() < 0.3:\n",
    "                text = re.sub(full, short, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    \n",
    "    def add_sms_abbreviations(self, text):\n",
    "        abbreviations = ['lol', 'brb', 'omg', 'tbh', 'idk', 'smh', 'imo', 'btw']\n",
    "        if random.random() < 0.3:\n",
    "            return text + ' ' + random.choice(abbreviations)\n",
    "        return text\n",
    "    \n",
    "    def vary_urgency_level(self, text):\n",
    "        urgency_phrases = [\n",
    "            'URGENT!', 'IMPORTANT!', 'ACT NOW!', 'LAST CHANCE!',\n",
    "            'FINAL NOTICE!', 'TIME SENSITIVE!', \"DON'T MISS OUT!\"\n",
    "        ]\n",
    "        if random.random() < 0.4:\n",
    "            return random.choice(urgency_phrases) + ' ' + text\n",
    "        return text\n",
    "    \n",
    "    def change_offer_amounts(self, text):\n",
    "        text = re.sub(r'\\$\\d+', f'${random.randint(10, 1000)}', text)\n",
    "        text = re.sub(r'\\d+\\s*pounds', f'{random.randint(50, 5000)} pounds', text)\n",
    "        text = re.sub(r'\\d+\\s*OMR', f'{random.randint(1, 100)} OMR', text)\n",
    "        return text\n",
    "    \n",
    "    def modify_urls_numbers(self, text):\n",
    "        text = re.sub(r'\\d{10,12}', ''.join([str(random.randint(0, 9)) for _ in range(10)]), text)\n",
    "        text = re.sub(r'http://\\S+|https://\\S+', 'http://example.com', text)\n",
    "        text = re.sub(r'www\\.\\S+', 'www.example.com', text)\n",
    "        return text\n",
    "\n",
    "    def augment_dataset(self, df, target_ham_count=6000, target_smish_count=3000):\n",
    "        \"\"\"\n",
    "        df must have columns: 'text' and numeric 'label' (0=ham, 1=smish).\n",
    "        If target_count < current_count, that class is not upsampled.\n",
    "        \"\"\"\n",
    "        augmented_data = []\n",
    "        \n",
    "        ham_df = df[df['label'] == 0]\n",
    "        smish_df = df[df['label'] == 1]\n",
    "        \n",
    "        print(f\"Original - Ham: {len(ham_df)}, Smish: {len(smish_df)}\")\n",
    "        \n",
    "        augmented_ham = self.augment_class(ham_df, target_ham_count, 'ham')\n",
    "        augmented_smish = self.augment_class(smish_df, target_smish_count, 'smish')\n",
    "        \n",
    "        final_df = pd.DataFrame(augmented_ham + augmented_smish)\n",
    "        print(f\"Augmented - Ham: {len(augmented_ham)}, Smish: {len(augmented_smish)}\")\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    def augment_class(self, class_df, target_count, label_name):\n",
    "        augmented_data = []\n",
    "        label = 0 if label_name == 'ham' else 1\n",
    "        \n",
    "        # keep original examples\n",
    "        for _, row in class_df.iterrows():\n",
    "            augmented_data.append({'text': row['text'], 'label': label})\n",
    "        \n",
    "        needed = target_count - len(class_df)\n",
    "        \n",
    "        if needed > 0:\n",
    "            print(f\"Augmenting {label_name} class: generating {needed} additional samples\")\n",
    "            \n",
    "            for _ in range(needed):\n",
    "                base_sample = class_df.sample(1).iloc[0]\n",
    "                base_text = base_sample['text']\n",
    "                augmented_texts = self.sms_specific_augmentation(base_text, label)\n",
    "                augmented_text = random.choice(augmented_texts)\n",
    "                \n",
    "                if augmented_text != base_text and len(augmented_text) > 10:\n",
    "                    augmented_data.append({'text': augmented_text, 'label': label})\n",
    "        \n",
    "        return augmented_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1434a9e2-fa8b-48ce-9e60-855a7c061828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 3: Generate Business Messages\n",
    "# ================================================================\n",
    "\n",
    "def generate_business_messages(num_messages=1500):\n",
    "    business_templates = [\n",
    "        \"Your {service} subscription for {amount} will renew on {date}. Manage in app.\",\n",
    "        \"Reminder: Your {service} plan expires on {date}. Update payment method.\",\n",
    "        \"Your {service} billing cycle ends {date}. Next charge: {amount}.\",\n",
    "        \"Your {bank} statement for {month} is ready. View online.\",\n",
    "        \"Payment of {amount} processed. Available balance: {balance}.\",\n",
    "        \"Security alert: New login to your {bank} account.\",\n",
    "        \"Dear students, {assignment} deadline extended to {date}.\",\n",
    "        \"Academic notice: {course} grades posted on student portal.\",\n",
    "        \"University update: {event} scheduled for {date}.\",\n",
    "        \"Order #{order_id} shipped! Track your delivery.\",\n",
    "        \"Delivery update: Package arriving today {time_range}.\",\n",
    "        \"Your return for order #{order_id} processed. Refund: {amount}.\",\n",
    "        \"Appointment reminder: {appointment_type} on {date} at {time}.\",\n",
    "        \"Prescription ready at {pharmacy}. Ref #: {ref_number}.\",\n",
    "        \"Test results for {test_name} available in patient portal.\"\n",
    "    ]\n",
    "    \n",
    "    services = ['Netflix', 'Spotify', 'Amazon Prime', 'YouTube Premium']\n",
    "    banks = ['Chase', 'Bank of America', 'Wells Fargo', 'Citibank']\n",
    "    amounts = ['$9.99', '$14.99', '$19.99', '$29.99']\n",
    "    dates = ['Nov 25, 2024', 'Dec 1, 2024', 'Jan 15, 2025']\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(num_messages):\n",
    "        template = random.choice(business_templates)\n",
    "        msg = template.format(\n",
    "            service=random.choice(services),\n",
    "            amount=random.choice(amounts),\n",
    "            date=random.choice(dates),\n",
    "            bank=random.choice(banks),\n",
    "            month=random.choice(['October', 'November', 'December']),\n",
    "            balance=random.choice(['$1,234.56', '$5,678.90']),\n",
    "            assignment=random.choice(['midterm project', 'final paper']),\n",
    "            course=random.choice(['Computer Science', 'Mathematics']),\n",
    "            event=random.choice(['career fair', 'guest lecture']),\n",
    "            order_id=f\"{random.choice(['A','B','C'])}{random.randint(100000,999999)}\",\n",
    "            time_range=random.choice(['2-4 PM', '10 AM-12 PM']),\n",
    "            appointment_type=random.choice(['dental cleaning', 'physical']),\n",
    "            time=random.choice(['10:00 AM', '2:30 PM']),\n",
    "            pharmacy=random.choice(['CVS', 'Walgreens']),\n",
    "            ref_number=f\"RX{random.randint(100000,999999)}\",\n",
    "            test_name=random.choice(['blood work', 'urinalysis'])\n",
    "        )\n",
    "        generated.append({'text': msg, 'label': 0})\n",
    "    \n",
    "    return pd.DataFrame(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a1a2a9d2-420d-4eda-97f8-99d2fb04f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 4: Load Cleaned Combined Dataset\n",
    "# ================================================================\n",
    "\n",
    "def load_cleaned_combined(path=\"combined_cleaned_original_datasets.csv\"):\n",
    "    \"\"\"\n",
    "    Load the pre-cleaned combined dataset.\n",
    "    Ensures we end up with columns: 'text' and numeric 'label' (0,1).\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"‚ùå File not found: {p}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(p)\n",
    "    print(f\"Loaded combined dataset from {p} with shape {df.shape}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Prefer numeric column if present\n",
    "    if \"label_num\" in df.columns:\n",
    "        df[\"label\"] = df[\"label_num\"]\n",
    "    \n",
    "    # Keep only needed columns\n",
    "    df = df[[\"text\", \"label\"]].copy()\n",
    "    \n",
    "    # Safety: ensure labels are 0/1 ints\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "    \n",
    "    print(\"\\nLabel distribution in base cleaned dataset:\")\n",
    "    print(df[\"label\"].value_counts().rename({0: \"ham\", 1: \"smish\"}))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9a6bef56-9596-48a4-9d9a-2f1b9479e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 5: Analyze URL Distribution in Dataset\n",
    "# ================================================================\n",
    "\n",
    "def analyze_urls_in_dataset(df):\n",
    "    \"\"\"Analyze URL patterns in your dataset (ham vs smish).\"\"\"\n",
    "    \n",
    "    url_pattern = re.compile(r'http://\\S+|https://\\S+|www\\.\\S+', re.IGNORECASE)\n",
    "    \n",
    "    ham_with_url = ham_without_url = 0\n",
    "    smish_with_url = smish_without_url = 0\n",
    "    \n",
    "    ham_urls = []\n",
    "    smish_urls = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        urls = re.findall(url_pattern, row['text'])\n",
    "        has_url = len(urls) > 0\n",
    "        \n",
    "        if row['label'] == 0:  # ham\n",
    "            if has_url:\n",
    "                ham_with_url += 1\n",
    "                ham_urls.extend(urls)\n",
    "            else:\n",
    "                ham_without_url += 1\n",
    "        else:  # smish\n",
    "            if has_url:\n",
    "                smish_with_url += 1\n",
    "                smish_urls.extend(urls)\n",
    "            else:\n",
    "                smish_without_url += 1\n",
    "    \n",
    "    total_ham = ham_with_url + ham_without_url\n",
    "    total_smish = smish_with_url + smish_without_url\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä URL DISTRIBUTION IN DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    if total_ham > 0:\n",
    "        print(f\"HAM with URL:      {ham_with_url:4d} ({ham_with_url/total_ham*100:.1f}%)\")\n",
    "        print(f\"HAM without URL:   {ham_without_url:4d} ({ham_without_url/total_ham*100:.1f}%)\")\n",
    "    if total_smish > 0:\n",
    "        print(f\"SMISH with URL:    {smish_with_url:4d} ({smish_with_url/total_smish*100:.1f}%)\")\n",
    "        print(f\"SMISH without URL: {smish_without_url:4d} ({smish_without_url/total_smish*100:.1f}%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüìé Sample HAM URLs (first 5):\")\n",
    "    for url in list(set(ham_urls))[:5]:\n",
    "        print(f\"  - {url}\")\n",
    "    \n",
    "    print(\"\\nüö® Sample SMISHING URLs (first 5):\")\n",
    "    for url in list(set(smish_urls))[:5]:\n",
    "        print(f\"  - {url}\")\n",
    "    \n",
    "    smish_url_percentage = smish_with_url / total_smish if total_smish > 0 else 0.0\n",
    "\n",
    "    '''\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if smish_url_percentage > 0.5:\n",
    "        print(\"‚úÖ RECOMMENDATION: Dataset has plenty of smishing URLs (>50%)\")\n",
    "        print(\"üìå Focus on adding HAM-with-URL examples only\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è RECOMMENDATION: Dataset has few smishing URLs (<50%)\")\n",
    "        print(\"üìå Consider adding both HAM-with-URL and SMISHING-with-URL\")\n",
    "    print(\"=\"*60)\n",
    "    '''\n",
    "    \n",
    "    return {\n",
    "        'ham_with_url': ham_with_url,\n",
    "        'ham_without_url': ham_without_url,\n",
    "        'smish_with_url': smish_with_url,\n",
    "        'smish_without_url': smish_without_url,\n",
    "        'smish_url_percentage': smish_url_percentage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ee194ea1-9ae1-4d74-baf9-73fbb1f325f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 6: URL-removal augmentation for smish\n",
    "# ================================================================\n",
    "\n",
    "def apply_smish_url_removal(df):\n",
    "    \"\"\"\n",
    "    For smish messages that contain URLs, create extra versions\n",
    "    where the URL is removed, to get smish-without-URL examples.\n",
    "    \"\"\"\n",
    "    url_pattern = re.compile(r'http://\\S+|https://\\S+|www\\.\\S+', re.IGNORECASE)\n",
    "    \n",
    "    new_rows = []\n",
    "    count_source = 0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"label\"] != 1:\n",
    "            continue\n",
    "        \n",
    "        text = row[\"text\"]\n",
    "        if re.search(url_pattern, text):\n",
    "            count_source += 1\n",
    "            no_url_text = re.sub(url_pattern, '', text).strip()\n",
    "            no_url_text = re.sub(r'\\s+', ' ', no_url_text)\n",
    "            if len(no_url_text) > 10 and no_url_text != text:\n",
    "                new_rows.append({\"text\": no_url_text, \"label\": 1})\n",
    "    \n",
    "    print(f\"Created {len(new_rows)} extra SMISH messages with URLs removed \"\n",
    "          f\"(from {count_source} original smish-with-URL messages).\")\n",
    "    \n",
    "    if new_rows:\n",
    "        df_out = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    else:\n",
    "        df_out = df.copy()\n",
    "    \n",
    "    print(\"Shape after smish URL-removal augmentation:\", df_out.shape)\n",
    "    print(df_out[\"label\"].value_counts().rename({0: \"ham\", 1: \"smish\"}))\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f6473c95-2a4d-4f6f-9dc6-e51a61c1fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 7: Generate Balanced Examples (HAM-with-URL + SMISH-without-URL)\n",
    "# ================================================================\n",
    "\n",
    "def generate_balanced_examples(num_ham=50, num_smish=50, smish_url_percentage=0):\n",
    "    \"\"\"\n",
    "    Generate balanced examples using templates.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    # ----- HAM with real-looking URLs -----\n",
    "    real_ham_domains = [\n",
    "        'squ.edu.om',\n",
    "        'omantel.om',\n",
    "        'bankmuscat.com',\n",
    "        'omanair.com',\n",
    "        'amazon.com',\n",
    "        'paypal.com',\n",
    "        'google.com',\n",
    "        'microsoft.com',\n",
    "        'ups.com',\n",
    "        'fedex.com',\n",
    "        'dhl.com',\n",
    "        'netflix.com',\n",
    "        'spotify.com',\n",
    "    ]\n",
    "    \n",
    "    ham_url_templates = [\n",
    "        \"Track your order: https://track.{domain}\",\n",
    "        \"Your statement is ready: https://billing.{domain}\",\n",
    "        \"Log in to your portal: https://portal.{domain}\",\n",
    "        \"Verify your email: https://accounts.{domain}/verify\",\n",
    "        \"View your invoice: https://secure.{domain}/invoice\",\n",
    "        \"Manage your subscription: https://manage.{domain}\",\n",
    "        \"Shipment update: https://tracking.{domain}\",\n",
    "        \"Update your profile: https://profile.{domain}\",\n",
    "        \"Your receipt is available: https://receipts.{domain}\",\n",
    "        \"Check your schedule: https://calendar.{domain}\",\n",
    "    ]\n",
    "    \n",
    "    for _ in range(num_ham):\n",
    "        domain = random.choice(real_ham_domains)\n",
    "        template = random.choice(ham_url_templates)\n",
    "        message = template.format(domain=domain)\n",
    "        examples.append({'text': message, 'label': 0})\n",
    "    \n",
    "    # ----- SMISH without URL -----\n",
    "    smish_templates = [\n",
    "        \"ALERT: Your {account} has been {threat}. {action} now to avoid {consequence}.\",\n",
    "        \"We tried to deliver your {item} but failed. Reply with your {info} to reschedule.\",\n",
    "        \"Your {service} has been pre-approved! Send your {sensitive_info} to finalize the process.\",\n",
    "        \"FINAL WARNING: Your {service} will be {threat} unless you {action} now.\",\n",
    "        \"You have an unpaid {payment}. Reply YES to see the amount and avoid {consequence}.\",\n",
    "        \"Your account has been selected for a random {check}. Send your {info} to continue using the service.\",\n",
    "        \"Congratulations, you are our lucky winner! Reply with your {info} to claim your {prize}.\",\n",
    "        \"Due to suspicious activity, we need to verify your identity. Reply with your {sensitive_info}.\",\n",
    "        \"Your {service} will be {threat} in 24 hours. Reply with your {info} to avoid disconnection.\",\n",
    "        \"{urgency}: Your {account} requires immediate verification. {action} to prevent {consequence}.\",\n",
    "        \"You've been selected for a {prize}. Text {keyword} to this number to collect your reward.\",\n",
    "    ]\n",
    "    \n",
    "    smish_accounts = ['bank account', 'credit card', 'PayPal account', 'account', 'mobile account']\n",
    "    smish_threats = ['locked', 'suspended', 'blocked', 'frozen', 'deactivated', 'terminated']\n",
    "    smish_actions = ['Call', 'Text', 'Reply', 'Confirm', 'Verify', 'Update']\n",
    "    smish_consequences = ['closure', 'legal action', 'permanent suspension', 'account termination', 'service loss']\n",
    "    smish_items = ['package', 'parcel', 'order', 'delivery', 'shipment']\n",
    "    smish_info = ['full name and ID number', 'personal details', 'ID number', 'full name', 'date of birth']\n",
    "    smish_services = ['loan', 'credit card', 'mobile number', 'SIM card', 'phone service']\n",
    "    smish_sensitive_info = ['salary details', 'date of birth', 'national ID', 'bank details', 'PIN']\n",
    "    smish_payments = ['fine', 'bill', 'invoice', 'charge', 'payment']\n",
    "    smish_checks = ['security check', 'verification', 'audit', 'review']\n",
    "    smish_prizes = ['prize', 'reward', 'gift card', 'cash prize', 'iPhone']\n",
    "    smish_urgency = ['URGENT', 'ALERT', 'WARNING', 'IMMEDIATE ACTION REQUIRED', 'FINAL NOTICE']\n",
    "    smish_keywords = ['CLAIM', 'WIN', 'YES', 'CONFIRM', 'VERIFY']\n",
    "    \n",
    "    for _ in range(num_smish):\n",
    "        template = random.choice(smish_templates)\n",
    "        message = template.format(\n",
    "            account=random.choice(smish_accounts),\n",
    "            threat=random.choice(smish_threats),\n",
    "            action=random.choice(smish_actions),\n",
    "            consequence=random.choice(smish_consequences),\n",
    "            item=random.choice(smish_items),\n",
    "            info=random.choice(smish_info),\n",
    "            service=random.choice(smish_services),\n",
    "            sensitive_info=random.choice(smish_sensitive_info),\n",
    "            payment=random.choice(smish_payments),\n",
    "            check=random.choice(smish_checks),\n",
    "            prize=random.choice(smish_prizes),\n",
    "            urgency=random.choice(smish_urgency),\n",
    "            keyword=random.choice(smish_keywords)\n",
    "        )\n",
    "        examples.append({'text': message, 'label': 1})\n",
    "    \n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "\n",
    "def add_balanced_examples(df: pd.DataFrame, url_stats: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add balanced examples based on URL analysis.\n",
    "    \n",
    "    - Generate ham messages WITH URLs so that:\n",
    "      ham_with_url_final ‚âà smish_with_url (from url_stats)\n",
    "    - Also generate some extra smish-without-URL messages.\n",
    "    \"\"\"\n",
    "    total_messages = len(df)\n",
    "    \n",
    "    # From analyze_urls_in_dataset()\n",
    "    ham_with_url = url_stats['ham_with_url']\n",
    "    smish_with_url = url_stats['smish_with_url']\n",
    "    \n",
    "    # üéØ Target: ham_with_url_final ‚âà smish_with_url\n",
    "    target_ham_with_url = smish_with_url\n",
    "    num_ham = max(0, target_ham_with_url - ham_with_url)\n",
    "    \n",
    "    # Still add some extra smish-without-URL (1‚Äì2% of dataset)\n",
    "    num_smish = max(50, int(total_messages * 0.015))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generating {num_ham} ham-with-URL and {num_smish} smish-without-URL examples...\")\n",
    "    \n",
    "    extra_df = generate_balanced_examples(\n",
    "        num_ham=num_ham,\n",
    "        num_smish=num_smish,\n",
    "        smish_url_percentage=url_stats['smish_url_percentage']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Adding {len(extra_df)} balanced examples.\")\n",
    "    df_out = pd.concat([df, extra_df], ignore_index=True)\n",
    "    print(f\"üìä After adding balanced examples: {df_out.shape}\")\n",
    "    print(df_out['label'].value_counts().rename({0: 'ham', 1: 'smish'}))\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "23c4471c-832a-4389-aad2-4baffe86acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CELL 8: Main Pipeline (UPDATED to use combined_cleaned_original_datasets.csv)\n",
    "# ================================================================\n",
    "\n",
    "def run_preprocessing():\n",
    "    COMBINED_PATH = \"combined_cleaned_original_datasets.csv\"\n",
    "    OUT_DIR = Path(\"prep_out\")\n",
    "    OUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 1) Load base cleaned dataset\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: LOADING CLEANED COMBINED DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    df = load_cleaned_combined(COMBINED_PATH)\n",
    "    if df is None:\n",
    "        return\n",
    "    print(f\"\\n‚úÖ Base cleaned dataset: {df.shape}\")\n",
    "    \n",
    "    df.to_csv(OUT_DIR / \"cleaned_base.csv\", index=False)\n",
    "    print(f\"üíæ Saved base cleaned dataset to: {OUT_DIR / 'cleaned_base.csv'}\")\n",
    "\n",
    "    # --- Ratio for ORIGINAL CLEANED DATASET ---\n",
    "    ham = (df['label'] == 0).sum()\n",
    "    smish = (df['label'] == 1).sum()\n",
    "    ratio = ham / smish\n",
    "    \n",
    "    print(\"\\n--- BALANCE REPORT: ORIGINAL DATASET ---\")\n",
    "    print(f\"HAM:   {ham}\")\n",
    "    print(f\"SMISH: {smish}\")\n",
    "    print(f\"Ratio (HAM : SMISH) = {ratio:.2f} : 1\")\n",
    "    print(\"Description: The original dataset is imbalanced, with ham messages more frequent than smishing messages.\")\n",
    "\n",
    "    \n",
    "    # 2) Analyze URL distribution\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: ANALYZING URL DISTRIBUTION\")\n",
    "    print(\"=\"*60)\n",
    "    url_stats = analyze_urls_in_dataset(df)\n",
    "    \n",
    "    # 3) Generate extra ham business messages\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 3: GENERATING BUSINESS MESSAGES\")\n",
    "    print(\"=\"*60)\n",
    "    business_df = generate_business_messages(num_messages=1500)\n",
    "    print(f\"üì® Generated business ham messages: {business_df.shape}\")\n",
    "    \n",
    "    df_base = pd.concat([df, business_df], ignore_index=True)\n",
    "    df_base = df_base.drop_duplicates(subset=[\"text\", \"label\"]).reset_index(drop=True)\n",
    "    print(f\"üîπ After adding business messages: {df_base.shape}\")\n",
    "    print(df_base[\"label\"].value_counts().rename({0: \"ham\", 1: \"smish\"}))\n",
    "\n",
    "    # --- Ratio AFTER BUSINESS MESSAGES ---\n",
    "    ham = (df_base['label'] == 0).sum()\n",
    "    smish = (df_base['label'] == 1).sum()\n",
    "    ratio = ham / smish\n",
    "    \n",
    "    print(\"\\n--- BALANCE REPORT: AFTER BUSINESS MESSAGES ---\")\n",
    "    print(f\"HAM:   {ham}\")\n",
    "    print(f\"SMISH: {smish}\")\n",
    "    print(f\"Ratio (HAM : SMISH) = {ratio:.2f} : 1\")\n",
    "    print(\"Description: Business HAM messages added realistic ham-with-URL examples, increasing ham count and improving class diversity.\")\n",
    "\n",
    "    \n",
    "    # 4) Apply SimpleSMSAugmenter\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 4: APPLYING SMS AUGMENTATION\")\n",
    "    print(\"=\"*60)\n",
    "    augmenter = SimpleSMSAugmenter()\n",
    "    augmented_df = augmenter.augment_dataset(\n",
    "        df_base,\n",
    "        target_ham_count=6000,   # ham already large, so mostly affects smish\n",
    "        target_smish_count=3000\n",
    "    )\n",
    "    print(f\"üîπ After SimpleSMSAugmenter: {augmented_df.shape}\")\n",
    "    print(augmented_df[\"label\"].value_counts().rename({0: \"ham\", 1: \"smish\"}))\n",
    "\n",
    "    # --- Ratio AFTER SMS AUGMENTER ---\n",
    "    ham = (augmented_df['label'] == 0).sum()\n",
    "    smish = (augmented_df['label'] == 1).sum()\n",
    "    ratio = ham / smish\n",
    "    \n",
    "    print(\"\\n--- BALANCE REPORT: AFTER SimpleSMSAugmenter ---\")\n",
    "    print(f\"HAM:   {ham}\")\n",
    "    print(f\"SMISH: {smish}\")\n",
    "    print(f\"Ratio (HAM : SMISH) = {ratio:.2f} : 1\")\n",
    "    print(\"Description: SMSAugmenter increased both classes. Smish was upsampled more heavily to reduce imbalance.\")\n",
    "\n",
    "    \n",
    "    # 5) URL-removal augmentation for smish\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 5: APPLYING URL REMOVAL FOR SMISHING\")\n",
    "    print(\"=\"*60)\n",
    "    augmented_df = apply_smish_url_removal(augmented_df)\n",
    "\n",
    "    # --- Ratio AFTER SMISH URL-REMOVAL AUGMENTATION ---\n",
    "    ham = (augmented_df['label'] == 0).sum()\n",
    "    smish = (augmented_df['label'] == 1).sum()\n",
    "    ratio = ham / smish\n",
    "    \n",
    "    print(\"\\n--- BALANCE REPORT: AFTER SMISH URL-REMOVAL ---\")\n",
    "    print(f\"HAM:   {ham}\")\n",
    "    print(f\"SMISH: {smish}\")\n",
    "    print(f\"Ratio (HAM : SMISH) = {ratio:.2f} : 1\")\n",
    "    print(\"Description: URL-removal generated additional smish-without-URL messages, improving linguistic variety in smishing examples.\")\n",
    "\n",
    "    \n",
    "    # 6) Add balanced examples (HAM-with-URL + SMISH-without-URL)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 6: ADDING BALANCED EXAMPLES\")\n",
    "    print(\"=\"*60)\n",
    "    final_df = add_balanced_examples(augmented_df, url_stats)\n",
    "\n",
    "    # --- Ratio AFTER BALANCED EXAMPLES ---\n",
    "    ham = (final_df['label'] == 0).sum()\n",
    "    smish = (final_df['label'] == 1).sum()\n",
    "    ratio = ham / smish\n",
    "    \n",
    "    print(\"\\n--- BALANCE REPORT: AFTER BALANCED EXAMPLES ---\")\n",
    "    print(f\"HAM:   {ham}\")\n",
    "    print(f\"SMISH: {smish}\")\n",
    "    print(f\"Ratio (HAM : SMISH) = {ratio:.2f} : 1\")\n",
    "    print(\"Description: Balanced examples added HAM-with-URL and SMISH-without-URL samples, stabilizing class distribution while maintaining realism.\")\n",
    "\n",
    "    \n",
    "    # 7) Final dedup + shuffle\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 7: FINAL CLEANUP\")\n",
    "    print(\"=\"*60)\n",
    "    final_df = final_df.drop_duplicates(subset=[\"text\", \"label\"])\n",
    "    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"üîπ After deduplication and shuffle: {final_df.shape}\")\n",
    "\n",
    "    # üîç NEW: Analyze URL distribution AFTER all augmentations & cleanup\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 7B: ANALYZING URL DISTRIBUTION AFTER FINAL CLEANUP\")\n",
    "    print(\"=\"*60)\n",
    "    final_url_stats = analyze_urls_in_dataset(final_df)\n",
    "    \n",
    "    # 8) Train/Val/Test split\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 8: SPLITTING INTO TRAIN/VAL/TEST\")\n",
    "    print(\"=\"*60)\n",
    "    train_df, test_df = train_test_split(\n",
    "        final_df,\n",
    "        test_size=0.2,\n",
    "        stratify=final_df[\"label\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.1,\n",
    "        stratify=train_df[\"label\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 9) Save outputs\n",
    "    final_df.to_csv(OUT_DIR / \"augmented_full_dataset.csv\", index=False)\n",
    "    train_df.to_csv(OUT_DIR / \"train.csv\", index=False)\n",
    "    val_df.to_csv(OUT_DIR / \"val.csv\", index=False)\n",
    "    test_df.to_csv(OUT_DIR / \"test.csv\", index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ PREPROCESSING COMPLETED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total:  {len(final_df):5d} messages\")\n",
    "    print(f\"Train:  {len(train_df):5d} messages\")\n",
    "    print(f\"Val:    {len(val_df):5d} messages\")\n",
    "    print(f\"Test:   {len(test_df):5d} messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b976396d-6bcc-4735-833c-5450c9bf31d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: LOADING CLEANED COMBINED DATASET\n",
      "============================================================\n",
      "Loaded combined dataset from combined_cleaned_original_datasets.csv with shape (5944, 3)\n",
      "Columns: ['label', 'text', 'label_num']\n",
      "\n",
      "Label distribution in base cleaned dataset:\n",
      "label\n",
      "ham      5025\n",
      "smish     919\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Base cleaned dataset: (5944, 2)\n",
      "üíæ Saved base cleaned dataset to: prep_out\\cleaned_base.csv\n",
      "\n",
      "--- BALANCE REPORT: ORIGINAL DATASET ---\n",
      "HAM:   5025\n",
      "SMISH: 919\n",
      "Ratio (HAM : SMISH) = 5.47 : 1\n",
      "Description: The original dataset is imbalanced, with ham messages more frequent than smishing messages.\n",
      "\n",
      "============================================================\n",
      "STEP 2: ANALYZING URL DISTRIBUTION\n",
      "============================================================\n",
      "============================================================\n",
      "üìä URL DISTRIBUTION IN DATASET\n",
      "============================================================\n",
      "HAM with URL:         3 (0.1%)\n",
      "HAM without URL:   5022 (99.9%)\n",
      "SMISH with URL:     134 (14.6%)\n",
      "SMISH without URL:  785 (85.4%)\n",
      "============================================================\n",
      "\n",
      "üìé Sample HAM URLs (first 5):\n",
      "  - www.fullonsms.com\n",
      "\n",
      "üö® Sample SMISHING URLs (first 5):\n",
      "  - https://ukhmrc-tax-refund.comÔøΩto\n",
      "  - www.txt82228.com.\n",
      "  - http://www.e-tlp.co.uk/expressoffer\n",
      "  - www.phb1.com\n",
      "  - www.movietrivia.tv\n",
      "\n",
      "============================================================\n",
      "STEP 3: GENERATING BUSINESS MESSAGES\n",
      "============================================================\n",
      "üì® Generated business ham messages: (1500, 2)\n",
      "üîπ After adding business messages: (6415, 2)\n",
      "label\n",
      "ham      5496\n",
      "smish     919\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- BALANCE REPORT: AFTER BUSINESS MESSAGES ---\n",
      "HAM:   5496\n",
      "SMISH: 919\n",
      "Ratio (HAM : SMISH) = 5.98 : 1\n",
      "Description: Business HAM messages added realistic ham-with-URL examples, increasing ham count and improving class diversity.\n",
      "\n",
      "============================================================\n",
      "STEP 4: APPLYING SMS AUGMENTATION\n",
      "============================================================\n",
      "Original - Ham: 5496, Smish: 919\n",
      "Augmenting ham class: generating 504 additional samples\n",
      "Augmenting smish class: generating 2081 additional samples\n",
      "Augmented - Ham: 5800, Smish: 1853\n",
      "üîπ After SimpleSMSAugmenter: (7653, 2)\n",
      "label\n",
      "ham      5800\n",
      "smish    1853\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- BALANCE REPORT: AFTER SimpleSMSAugmenter ---\n",
      "HAM:   5800\n",
      "SMISH: 1853\n",
      "Ratio (HAM : SMISH) = 3.13 : 1\n",
      "Description: SMSAugmenter increased both classes. Smish was upsampled more heavily to reduce imbalance.\n",
      "\n",
      "============================================================\n",
      "STEP 5: APPLYING URL REMOVAL FOR SMISHING\n",
      "============================================================\n",
      "Created 304 extra SMISH messages with URLs removed (from 304 original smish-with-URL messages).\n",
      "Shape after smish URL-removal augmentation: (7957, 2)\n",
      "label\n",
      "ham      5800\n",
      "smish    2157\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- BALANCE REPORT: AFTER SMISH URL-REMOVAL ---\n",
      "HAM:   5800\n",
      "SMISH: 2157\n",
      "Ratio (HAM : SMISH) = 2.69 : 1\n",
      "Description: URL-removal generated additional smish-without-URL messages, improving linguistic variety in smishing examples.\n",
      "\n",
      "============================================================\n",
      "STEP 6: ADDING BALANCED EXAMPLES\n",
      "============================================================\n",
      "\n",
      "‚úÖ Generating 131 ham-with-URL and 119 smish-without-URL examples...\n",
      "‚úÖ Adding 250 balanced examples.\n",
      "üìä After adding balanced examples: (8207, 2)\n",
      "label\n",
      "ham      5931\n",
      "smish    2276\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- BALANCE REPORT: AFTER BALANCED EXAMPLES ---\n",
      "HAM:   5931\n",
      "SMISH: 2276\n",
      "Ratio (HAM : SMISH) = 2.61 : 1\n",
      "Description: Balanced examples added HAM-with-URL and SMISH-without-URL samples, stabilizing class distribution while maintaining realism.\n",
      "\n",
      "============================================================\n",
      "STEP 7: FINAL CLEANUP\n",
      "============================================================\n",
      "üîπ After deduplication and shuffle: (8007, 2)\n",
      "\n",
      "============================================================\n",
      "STEP 7B: ANALYZING URL DISTRIBUTION AFTER FINAL CLEANUP\n",
      "============================================================\n",
      "============================================================\n",
      "üìä URL DISTRIBUTION IN DATASET\n",
      "============================================================\n",
      "HAM with URL:        90 (1.5%)\n",
      "HAM without URL:   5793 (98.5%)\n",
      "SMISH with URL:     271 (12.8%)\n",
      "SMISH without URL: 1853 (87.2%)\n",
      "============================================================\n",
      "\n",
      "üìé Sample HAM URLs (first 5):\n",
      "  - https://secure.spotify.com/invoice\n",
      "  - https://track.paypal.com\n",
      "  - https://billing.amazon.com\n",
      "  - https://manage.bankmuscat.com\n",
      "  - https://accounts.google.com/verify\n",
      "\n",
      "üö® Sample SMISHING URLs (first 5):\n",
      "  - https://ukhmrc-tax-refund.comÔøΩto\n",
      "  - www.txt82228.com.\n",
      "  - http://www.e-tlp.co.uk/expressoffer\n",
      "  - www.phb1.com\n",
      "  - www.movietrivia.tv\n",
      "\n",
      "============================================================\n",
      "STEP 8: SPLITTING INTO TRAIN/VAL/TEST\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üéØ PREPROCESSING COMPLETED!\n",
      "============================================================\n",
      "Total:   8007 messages\n",
      "Train:   5764 messages\n",
      "Val:      641 messages\n",
      "Test:    1602 messages\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# CELL 9: Execute Preprocessing\n",
    "# ================================================================\n",
    "\n",
    "run_preprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7b39d-1102-4e11-a9fb-c815071b2ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
